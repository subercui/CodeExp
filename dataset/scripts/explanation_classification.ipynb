{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a classification model and use the model to filter in good explanations to form a dataset\n",
    "\n",
    "The script is inspired by [Fine-tuning with custom datasets](https://huggingface.co/transformers/v4.10.1/custom_datasets.html), and the [colab notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/pytorch/custom_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>reference_code</th>\n",
       "      <th>complexity</th>\n",
       "      <th>rouge-1-r</th>\n",
       "      <th>rouge-1-f</th>\n",
       "      <th>explanation quality (high-1/low-0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>Multifactorial of n of order k, n(!!...!). \\n ...</td>\n",
       "      <td>def factorialk(n, k, exact=True): \\n   if exac...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>Issues an HTTP redirect to the given relative ...</td>\n",
       "      <td>def redirect(uri, permanent=False, abort=False...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>Return a list of installed packages either glo...</td>\n",
       "      <td>def freeze(bin_env=None, user=None, cwd=None, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>Returns a RNG object. \\n Parameters \\n rng_or_...</td>\n",
       "      <td>def make_rng(rng_or_seed=None, default_seed=No...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>Turns a sequence iterator or list into a dicti...</td>\n",
       "      <td>def to_dict(sequences, key_function=None): \\n ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0         199  Multifactorial of n of order k, n(!!...!). \\n ...   \n",
       "1          49  Issues an HTTP redirect to the given relative ...   \n",
       "2         201  Return a list of installed packages either glo...   \n",
       "3         126  Returns a RNG object. \\n Parameters \\n rng_or_...   \n",
       "4          92  Turns a sequence iterator or list into a dicti...   \n",
       "\n",
       "                                      reference_code  complexity  rouge-1-r  \\\n",
       "0  def factorialk(n, k, exact=True): \\n   if exac...           5   0.400000   \n",
       "1  def redirect(uri, permanent=False, abort=False...          10   0.309091   \n",
       "2  def freeze(bin_env=None, user=None, cwd=None, ...           5   0.303797   \n",
       "3  def make_rng(rng_or_seed=None, default_seed=No...           7   0.294118   \n",
       "4  def to_dict(sequences, key_function=None): \\n ...           4   0.266667   \n",
       "\n",
       "   rouge-1-f  explanation quality (high-1/low-0)  \n",
       "0   0.242424                                   1  \n",
       "1   0.229730                                   1  \n",
       "2   0.292683                                   1  \n",
       "3   0.175439                                   1  \n",
       "4   0.163265                                   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset in csv\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.split(cwd)[0]\n",
    "df = pd.read_csv(os.path.join(parent_dir, 'ExplanationsQualityMarked.valid.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'description', 'reference_code', 'complexity',\n",
       "       'rouge-1-r', 'rouge-1-f', 'explanation quality (high-1/low-0)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT classifier with the trainer api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of all samples: 269\n"
     ]
    }
   ],
   "source": [
    "train_texts, train_labels = df[\"description\"].tolist(), df[\"explanation quality (high-1/low-0)\"].tolist()\n",
    "print(f\"num of all samples: {len(train_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of training samples: 215\n",
      "num of validation samples: 54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "# use validation set as the test set\n",
    "test_texts, test_labels = val_texts, val_labels\n",
    "assert len(train_texts) > 200\n",
    "print(f\"num of training samples: {len(train_texts)}\")\n",
    "print(f\"num of validation samples: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply pass our texts to the tokenizer. Weâ€™ll pass truncation=True and padding=True, which will ensure that all of our sequences are padded to the same length and are truncated to be no longer modelâ€™s maximum input length. This will allow us to feed batches of sequences into the model at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding is set to false. We add tokenizer option to the trainer later and the \n",
    "# input will be padded to the max length there.\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=False)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=False)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ExplanationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ExplanationDataset(train_encodings, train_labels)\n",
    "val_dataset = ExplanationDataset(val_encodings, val_labels)\n",
    "test_dataset = ExplanationDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning with Trainer\n",
    "The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model\n",
    "to fine-tune, define the `TrainingArguments`/`TFTrainingArguments` and\n",
    "instantiate a `Trainer`/`TFTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer parameters\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 215\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 80/140 01:28 < 01:08, 0.88 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.702700</td>\n",
       "      <td>0.687836</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.676051</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>0.649178</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>0.627274</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.566600</td>\n",
       "      <td>0.589476</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.574779</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.578691</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Model weights saved in ./results/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Model weights saved in ./results/checkpoint-20/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-20/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Model weights saved in ./results/checkpoint-30/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-30/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-30/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-40\n",
      "Configuration saved in ./results/checkpoint-40/config.json\n",
      "Model weights saved in ./results/checkpoint-40/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-40/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-50/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-60\n",
      "Configuration saved in ./results/checkpoint-60/config.json\n",
      "Model weights saved in ./results/checkpoint-60/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-60/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-60/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-70\n",
      "Configuration saved in ./results/checkpoint-70/config.json\n",
      "Model weights saved in ./results/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-70/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-80\n",
      "Configuration saved in ./results/checkpoint-80/config.json\n",
      "Model weights saved in ./results/checkpoint-80/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-80/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-40 (score: 0.7605633802816901).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.6054039359092712, metrics={'train_runtime': 88.8492, 'train_samples_per_second': 24.198, 'train_steps_per_second': 1.576, 'total_flos': 137585763006804.0, 'train_loss': 0.6054039359092712, 'epoch': 5.71})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    # warmup_ratio=0.1,                 # ratio of learning rate for warmup\n",
    "    # do not use warmup_steps if warmup_ratio is set\n",
    "    # warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=1e-5,               # initial learning rate\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    tokenizer=tokenizer,                 # tokenizer\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='232' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try predict on test set\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply model on the full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>reference_code</th>\n",
       "      <th>complexity</th>\n",
       "      <th>rouge-1-r</th>\n",
       "      <th>rouge-1-f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pulls all flashed messages from the session an...</td>\n",
       "      <td>def get_flashed_messages(with_categories=False...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.078740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yield images of the laplacian pyramid formed b...</td>\n",
       "      <td>def pyramid_laplacian(image, max_layer=(-1), d...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.101852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Import module by name \\n :param name: \\n Modul...</td>\n",
       "      <td>def import_module(name, required=True): \\n   t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given a DataSource, generates a dictionary tha...</td>\n",
       "      <td>def mapping(data_source, geom_name='geom', lay...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Store a temporary file. \\n @param filedata: co...</td>\n",
       "      <td>def store_temp_file(filedata, filename, path=N...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Pulls all flashed messages from the session an...   \n",
       "1  Yield images of the laplacian pyramid formed b...   \n",
       "2  Import module by name \\n :param name: \\n Modul...   \n",
       "3  Given a DataSource, generates a dictionary tha...   \n",
       "4  Store a temporary file. \\n @param filedata: co...   \n",
       "\n",
       "                                      reference_code  complexity  rouge-1-r  \\\n",
       "0  def get_flashed_messages(with_categories=False...           6   0.161290   \n",
       "1  def pyramid_laplacian(image, max_layer=(-1), d...           5   0.161765   \n",
       "2  def import_module(name, required=True): \\n   t...           4   0.150000   \n",
       "3  def mapping(data_source, geom_name='geom', lay...           6   0.160000   \n",
       "4  def store_temp_file(filedata, filename, path=N...           5   0.041667   \n",
       "\n",
       "   rouge-1-f  \n",
       "0   0.078740  \n",
       "1   0.101852  \n",
       "2   0.133333  \n",
       "3   0.153846  \n",
       "4   0.058824  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the train corpus\n",
    "df_all = pd.read_csv(os.path.join(parent_dir, 'long_code_desc.train.csv'), index_col=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of examples in full corpus: 13437\n"
     ]
    }
   ],
   "source": [
    "print(f\"num of examples in full corpus: {len(df_all)}\")\n",
    "corpus_texts, corpus_labels = df_all[\"description\"].tolist(), [1]*len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_encodings = tokenizer(corpus_texts, truncation=True, padding=True)\n",
    "corpus_dataset = ExplanationDataset(corpus_encodings, corpus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 13437\n",
      "  Batch size = 64\n"
     ]
    }
   ],
   "source": [
    "predictions, label_ids, metrics = trainer.predict(corpus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of qualified examples: 10369\n",
      "ratio of qualified examples: 0.7716752251246558\n"
     ]
    }
   ],
   "source": [
    "pred_quality = np.argmax(predictions, axis=1)\n",
    "assert len(pred_quality) == len(corpus_texts)\n",
    "print(f\"num of qualified examples: {sum(pred_quality)}\")\n",
    "print(f\"ratio of qualified examples: {sum(pred_quality)/len(pred_quality)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save qualified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"explanation quality (high-1/low-0)\"] = pred_quality\n",
    "# filter in qualified examples\n",
    "df_qualified = df_all[df_all[\"explanation quality (high-1/low-0)\"] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(parent_dir, 'QualifiedExplanations.train.csv')):\n",
    "    df_qualified.to_csv(os.path.join(parent_dir, 'QualifiedExplanations.train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a47bc436338522316c19d32302f1310671eb64ce2c075643d095463d867d9ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('copilot-2-PO7iTfBn-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
