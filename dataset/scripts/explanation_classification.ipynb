{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a classification model and use the model to filter in good explanations to form a dataset\n",
    "\n",
    "The script is inspired by [Fine-tuning with custom datasets](https://huggingface.co/transformers/v4.10.1/custom_datasets.html), and the [colab notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/master/transformers_doc/pytorch/custom_datasets.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>reference_code</th>\n",
       "      <th>complexity</th>\n",
       "      <th>rouge-1-r</th>\n",
       "      <th>rouge-1-f</th>\n",
       "      <th>explanation quality (high-1/low-0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199</td>\n",
       "      <td>Multifactorial of n of order k, n(!!...!). \\n ...</td>\n",
       "      <td>def factorialk(n, k, exact=True): \\n   if exac...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>Issues an HTTP redirect to the given relative ...</td>\n",
       "      <td>def redirect(uri, permanent=False, abort=False...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.229730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201</td>\n",
       "      <td>Return a list of installed packages either glo...</td>\n",
       "      <td>def freeze(bin_env=None, user=None, cwd=None, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>Returns a RNG object. \\n Parameters \\n rng_or_...</td>\n",
       "      <td>def make_rng(rng_or_seed=None, default_seed=No...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.175439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>Turns a sequence iterator or list into a dicti...</td>\n",
       "      <td>def to_dict(sequences, key_function=None): \\n ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        description  \\\n",
       "0         199  Multifactorial of n of order k, n(!!...!). \\n ...   \n",
       "1          49  Issues an HTTP redirect to the given relative ...   \n",
       "2         201  Return a list of installed packages either glo...   \n",
       "3         126  Returns a RNG object. \\n Parameters \\n rng_or_...   \n",
       "4          92  Turns a sequence iterator or list into a dicti...   \n",
       "\n",
       "                                      reference_code  complexity  rouge-1-r  \\\n",
       "0  def factorialk(n, k, exact=True): \\n   if exac...           5   0.400000   \n",
       "1  def redirect(uri, permanent=False, abort=False...          10   0.309091   \n",
       "2  def freeze(bin_env=None, user=None, cwd=None, ...           5   0.303797   \n",
       "3  def make_rng(rng_or_seed=None, default_seed=No...           7   0.294118   \n",
       "4  def to_dict(sequences, key_function=None): \\n ...           4   0.266667   \n",
       "\n",
       "   rouge-1-f  explanation quality (high-1/low-0)  \n",
       "0   0.242424                                   1  \n",
       "1   0.229730                                   1  \n",
       "2   0.292683                                   1  \n",
       "3   0.175439                                   1  \n",
       "4   0.163265                                   1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset in csv\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.split(cwd)[0]\n",
    "df = pd.read_csv(os.path.join(parent_dir, 'ExplanationsQualityMarked.valid.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'description', 'reference_code', 'complexity',\n",
       "       'rouge-1-r', 'rouge-1-f', 'explanation quality (high-1/low-0)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT classifier with the trainer api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of all samples: 269\n"
     ]
    }
   ],
   "source": [
    "train_texts, train_labels = df[\"description\"].tolist(), df[\"explanation quality (high-1/low-0)\"].tolist()\n",
    "print(f\"num of all samples: {len(train_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of training samples: 215\n",
      "num of validation samples: 54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "# use validation set as the test set\n",
    "test_texts, test_labels = val_texts, val_labels\n",
    "assert len(train_texts) > 200\n",
    "print(f\"num of training samples: {len(train_texts)}\")\n",
    "print(f\"num of validation samples: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can simply pass our texts to the tokenizer. We’ll pass truncation=True and padding=True, which will ensure that all of our sequences are padded to the same length and are truncated to be no longer model’s maximum input length. This will allow us to feed batches of sequences into the model at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding is set to false. We add tokenizer option to the trainer later and the \n",
    "# input will be padded to the max length there.\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=False)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=False)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ExplanationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = ExplanationDataset(train_encodings, train_labels)\n",
    "val_dataset = ExplanationDataset(val_encodings, val_labels)\n",
    "test_dataset = ExplanationDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning with Trainer\n",
    "The steps above prepared the datasets in the way that the trainer is expected. Now all we need to do is create a model\n",
    "to fine-tune, define the `TrainingArguments`/`TFTrainingArguments` and\n",
    "instantiate a `Trainer`/`TFTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer parameters\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 215\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 80/140 01:28 < 01:08, 0.88 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.702700</td>\n",
       "      <td>0.687836</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.676051</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.669300</td>\n",
       "      <td>0.665515</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>0.649178</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>0.627274</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.566600</td>\n",
       "      <td>0.589476</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.574779</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.578691</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Model weights saved in ./results/checkpoint-10/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-10/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-10/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Model weights saved in ./results/checkpoint-20/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-20/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-20/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Model weights saved in ./results/checkpoint-30/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-30/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-30/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-40\n",
      "Configuration saved in ./results/checkpoint-40/config.json\n",
      "Model weights saved in ./results/checkpoint-40/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-40/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-40/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-50/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-60\n",
      "Configuration saved in ./results/checkpoint-60/config.json\n",
      "Model weights saved in ./results/checkpoint-60/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-60/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-60/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-70\n",
      "Configuration saved in ./results/checkpoint-70/config.json\n",
      "Model weights saved in ./results/checkpoint-70/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-70/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-70/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-80\n",
      "Configuration saved in ./results/checkpoint-80/config.json\n",
      "Model weights saved in ./results/checkpoint-80/pytorch_model.bin\n",
      "tokenizer config file saved in ./results/checkpoint-80/tokenizer_config.json\n",
      "Special tokens file saved in ./results/checkpoint-80/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-40 (score: 0.7605633802816901).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.6054039359092712, metrics={'train_runtime': 88.8492, 'train_samples_per_second': 24.198, 'train_steps_per_second': 1.576, 'total_flos': 137585763006804.0, 'train_loss': 0.6054039359092712, 'epoch': 5.71})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    num_train_epochs=10,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    # warmup_ratio=0.1,                 # ratio of learning rate for warmup\n",
    "    # do not use warmup_steps if warmup_ratio is set\n",
    "    # warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    learning_rate=1e-5,               # initial learning rate\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,             # evaluation dataset\n",
    "    tokenizer=tokenizer,                 # tokenizer\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 54\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='232' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 02:51]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try predict on test set\n",
    "predictions, label_ids, metrics = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply model on the full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>reference_code</th>\n",
       "      <th>complexity</th>\n",
       "      <th>rouge-1-r</th>\n",
       "      <th>rouge-1-f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pulls all flashed messages from the session an...</td>\n",
       "      <td>def get_flashed_messages(with_categories=False...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.078740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yield images of the laplacian pyramid formed b...</td>\n",
       "      <td>def pyramid_laplacian(image, max_layer=(-1), d...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.101852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Import module by name \\n :param name: \\n Modul...</td>\n",
       "      <td>def import_module(name, required=True): \\n   t...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given a DataSource, generates a dictionary tha...</td>\n",
       "      <td>def mapping(data_source, geom_name='geom', lay...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Store a temporary file. \\n @param filedata: co...</td>\n",
       "      <td>def store_temp_file(filedata, filename, path=N...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  Pulls all flashed messages from the session an...   \n",
       "1  Yield images of the laplacian pyramid formed b...   \n",
       "2  Import module by name \\n :param name: \\n Modul...   \n",
       "3  Given a DataSource, generates a dictionary tha...   \n",
       "4  Store a temporary file. \\n @param filedata: co...   \n",
       "\n",
       "                                      reference_code  complexity  rouge-1-r  \\\n",
       "0  def get_flashed_messages(with_categories=False...           6   0.161290   \n",
       "1  def pyramid_laplacian(image, max_layer=(-1), d...           5   0.161765   \n",
       "2  def import_module(name, required=True): \\n   t...           4   0.150000   \n",
       "3  def mapping(data_source, geom_name='geom', lay...           6   0.160000   \n",
       "4  def store_temp_file(filedata, filename, path=N...           5   0.041667   \n",
       "\n",
       "   rouge-1-f  \n",
       "0   0.078740  \n",
       "1   0.101852  \n",
       "2   0.133333  \n",
       "3   0.153846  \n",
       "4   0.058824  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the train corpus\n",
    "df_all = pd.read_csv(os.path.join(parent_dir, 'long_code_desc.train.csv'), index_col=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of examples in full corpus: 13437\n"
     ]
    }
   ],
   "source": [
    "print(f\"num of examples in full corpus: {len(df_all)}\")\n",
    "corpus_texts, corpus_labels = df_all[\"description\"].tolist(), [1]*len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_encodings = tokenizer(corpus_texts, truncation=True, padding=True)\n",
    "corpus_dataset = ExplanationDataset(corpus_encodings, corpus_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 13437\n",
      "  Batch size = 64\n"
     ]
    }
   ],
   "source": [
    "predictions, label_ids, metrics = trainer.predict(corpus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of qualified examples: 10369\n",
      "ratio of qualified examples: 0.7716752251246558\n"
     ]
    }
   ],
   "source": [
    "pred_quality = np.argmax(predictions, axis=1)\n",
    "assert len(pred_quality) == len(corpus_texts)\n",
    "print(f\"num of qualified examples: {sum(pred_quality)}\")\n",
    "print(f\"ratio of qualified examples: {sum(pred_quality)/len(pred_quality)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save qualified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[\"explanation quality (high-1/low-0)\"] = pred_quality\n",
    "# filter in qualified examples\n",
    "df_qualified = df_all[df_all[\"explanation quality (high-1/low-0)\"] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(parent_dir, 'QualifiedExplanations.train.csv')):\n",
    "    df_qualified.to_csv(os.path.join(parent_dir, 'QualifiedExplanations.train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a47bc436338522316c19d32302f1310671eb64ce2c075643d095463d867d9ed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('copilot-2-PO7iTfBn-py3.8': poetry)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
